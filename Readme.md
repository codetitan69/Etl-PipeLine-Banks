# ETL Pipeline: Largest Banks Data Scraper

![ETL Pipeline](https://img.shields.io/badge/ETL-Pipeline-blue.svg) ![Python](https://img.shields.io/badge/Python-3.8%2B-brightgreen.svg) ![SQLite](https://img.shields.io/badge/Database-SQLite-orange.svg) ![Web Scraping](https://img.shields.io/badge/Web%20Scraping-BeautifulSoup-lightblue.svg)

## ğŸ“Œ Project Overview
This project is an **ETL (Extract, Transform, Load) pipeline** that scrapes market capitalization data of the world's largest banks from Wikipedia, converts the values into different currencies, and stores the results in both CSV format and an SQLite database.

## âœ¨ Features
- **Web Scraping**: Extracts bank data using `requests` and `BeautifulSoup`
- **Data Transformation**: Converts market capitalization (USD) to GBP, EUR, and INR using exchange rates
- **Database Storage**: Saves the transformed data into an SQLite database
- **Logging**: Implements error handling and logs progress for debugging
- **CSV Export**: Saves the final processed data into a CSV file

## ğŸ›  Technologies Used
- **Python** ğŸ
- `requests` â€“ Fetches the Wikipedia page
- `BeautifulSoup` â€“ Parses and extracts tabular data
- `pandas` â€“ Processes and transforms data
- `sqlite3` â€“ Stores structured data in a relational database
- `logging` â€“ Captures execution logs for debugging

## ğŸ“‚ Project Structure
```plaintext
ğŸ“ Etl-PipeLine-Banks/
â”‚-- main.py                 # Main script for the ETL process
â”‚-- exchange_rate.csv       # Exchange rates for currency conversion
â”‚-- Banks.db                # SQLite database (generated after execution)
â”‚-- Largest_banks_data.csv  # Final processed data (generated after execution)
â”‚-- code_log.txt            # Execution log file
â”‚-- README.md               # Project documentation
```

## ğŸ”§ Installation & Usage
### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/codetitan69/Etl-PipeLine-Banks.git
cd Etl-PipeLine-Banks
```
### 2ï¸âƒ£ Install Dependencies
Ensure you have Python 3.8+ installed, then install the required libraries:
```bash
pip install requests pandas beautifulsoup4 sqlite3
```
### 3ï¸âƒ£ Run the ETL Pipeline
```bash
python main.py
```
### 4ï¸âƒ£ View the Results
- Processed data is saved in `Largest_banks_data.csv`
- Database file `Banks.db` contains structured data for queries
- Execution logs can be checked in `code_log.txt`

## ğŸ“Š SQL Queries
To run queries on the database, you can use:
```sql
SELECT * FROM Largest_banks;
SELECT AVG(MC_GBP_Billion) FROM Largest_banks;
SELECT Name FROM Largest_banks LIMIT 5;
```

## ğŸ“ Future Improvements
- Add support for more currencies
- Automate exchange rate fetching from an API
- Implement error handling for dynamic Wikipedia table changes

## ğŸ¤ Contributing
Feel free to fork this repository, raise issues, or suggest improvements! ğŸš€

## ğŸ“œ License
This project is open-source and available under the [MIT License](LICENSE).

---
ğŸ“Œ **Author**: [codetitan69](https://github.com/codetitan69)  
ğŸ“Œ **GitHub Repository**: [Etl-PipeLine-Banks](https://github.com/codetitan69/Etl-PipeLine-Banks)  
ğŸ“Œ **Feel free to â­ the repo if you found it useful!**
